% Performance testing +- same performance
% https://ieeexplore.ieee.org/abstract/document/8928192

% Performance testing +monolith
% https://ieeexplore.ieee.org/abstract/document/9109514

So far we have looked at three different types of architectural patterns. In this section we will look at the implementation of a simple application using all 3 architectural patterns discussed (Monolith, Mudulith, Microservice). We will look at the implications in terms of internal structure, database design, scalability and of course performance.

\section{Application}
This is an application example of a real world system consisting of HTTP API, database queries and business logic. It has been designed to be easy to understand and to solve a problem known to everyone: orders. Each application exposes the following HTTP API:
\begin{itemize}
    \item \textbf{Get /item} - Retrieve all existing items.
    \item \textbf{Get /item/\{itemId\}} - Retrieve an existing item specified by id.
    \item \textbf{Post /cart/items/\{itemId\}} - Add item to shopping cart.
          % \item \textbf{Delete /cart/items/\{itemId\}} - Remove item from shopping cart.
    \item \textbf{Post /order/create} - Create an order from items in shopping cart.
    \item \textbf{Get /order/\{orderId\}} - Retrieve order specified by id.
          % \item \textbf{Post /order/\{orderId\}/cancel} - Cancel order specified by id.
    \item \textbf{Get /invoice/\{invoiceId\}} - Retrieve invoice specified by id.
    \item \textbf{Get /payment/\{paymentId\}} - Retrieve payment specified by id.
    \item \textbf{Post /payment/invoice/\{invoiceId\}} - Pay for invoice specified by id.
\end{itemize}

The Client of the application can view items, add them to his shopping cart, place an order, retrieve an invoice and pay for it. Like most of the applications today, there are mainly operations querying data or saving data into database. The activity flow is described on Figure~\ref{img:app_activity_flow}. First, a session is created for the client, then the client loads items and adds everything he wants to his shopping cart. Later the client places an order, an invoice is generated in the background and the client can cancel the order or pay for it. To add more CPU intensive tasks, invoice generates PDF and also calculates 41st Fibonacci number.

Candidates for the implementation programming language were Rust and Golang due to its minimal runtime (minimal impact on benchmarking). Winner is Golang because it's easier to use, good personal experience of the authors and better support for the Open Tracing project, which is used for monitoring from within the application during benchmarking. All applications are based on \textit{gorilla/mux} \cite{MUX} for http server + request routing library and \textit{Bun} \cite{BUN} as a lightweight ORM.

PostgreSQL was chosen as the data store because SQL databases are more widely known than NoSQL, so it should be easier for anyone to understand the design. It was chosen because of its current popularity and the authors' preference for it over MySQL.
\begin{figure}
    \centering
    \includesvg{images/app_activity.svg}
    \caption{Diagram describes client flow of application. \label{img:app_activity_flow}}
\end{figure}

The application needs to be able to run in multiple instances so that it can be properly benchmarked and scaled later. In order to run the application in multiple instances, a container orchestrator will need to be used. Instead of adding unnecessary complexity when using Kubernetes, I decided to use \textit{docker compose} to manage containers, as I do not plan to run the application on multiple nodes. All requests are sent to Nginx, which acts as both a reverse proxy and a load balancer.


\section{Monolith example}
This example is implemented as a monolithic system. Basically it is a three tier application: presentation (HTTP API), application and data (database). Figure~\ref{img:monolith_db_schema} describes the internal structure of the application packages. \textit{Routes} package contains path mapping for endpoint handlers defined in \textit{endpoints}. Handlers contain simple logic definition, more complex logic is in \textit{services} and data manipulation around the database is in \textit{database}.

\begin{figure}
    \centering
    \includesvg[width=0.7\textwidth]{images/monolith_package.svg}
    \caption{Internal package structure of Monolithic example. \label{img:monolith_package}}
\end{figure}


\subsection{Database}
Due to the nature of Monolith as a unified system, all data resides within a single database, making full use of constraints and referential integrity, thus ensuring data consistency. Complete database schema is shown on diagram~\ref{img:monolith_db_schema} consisting of 7 tables, five of which are entity tables and two are entity relationship mapping. The application will have a database pool consisting of a maximum of 8 connections.

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{images/monolith_db_schema.png}
    \caption{Database schema displaying tables and relations of Monolithic example. \label{img:monolith_db_schema}}
\end{figure}



\section{Modulith example}
This is an example of using the modular monolith approach. The original monolithic application has been split into several smaller monoliths called \textit{modules}. The size of each module depends on the specificity of the project. In this case, it is almost equivalent to one module per database entity, except for the shopping cart and items, which have been merged into a single module to demonstrate the possibility of having modules with a larger volume. Package schema and dependencies are shown in diagram~\ref{img:modulith_package}.

Each module has the same internal structure as the original Monolith plus exposes its API with an interface (Diagram~\ref{img:modulith_module_package}). Modules encapsulate their own data storage, and there should be no cross-module table constraints in the database, although this is possible, it doesn't make sense from a logical separation perspective. It should be possible for each module to use a different database and even a different database technology. In the case of the largest module, which contains the shopping cart and items, foreign key constraints are preserved because it resides within a single module.

Modules can use API of other modules, although this should be limited as much as possible to keep coupling low. The dependency on other modules is defined through the use of interfaces, and the actual implementation can either be automatically injected using the IoC approach, or as in this case, just define a top level module that takes care of initialising individual modules and spinning up a single HTTP server.

Scaling Modulith once we have identified the bottleneck packages is very easy. Since each module is essentially a small monolith, it can be moved into service and run independently. It just needs to expose its API over the network, such as gRPC or just a simple HTTP API. This network exposure can be generated automatically if all objects in the interface are serialisable. Later client instances will be passed to all dependent modules and from the point of view of other modules nothing changes, only now the underlying communication will not be inter-process communication but network communication. The implementation could even be fully automated in a declarative way. The package can be moved to a separate service and scaled, simply by changing the configuration.

In this particular example, the implementation to expose the capabilities defined in the invoice interface was created manually by defining the following additional HTTP endpoints and thus implementing a client to satisfy the existing interface.

\begin{itemize}
    \item \textbf{Post /invoice} - Generate invoice for order specified in body.
    \item \textbf{Patch /invoice/\{invoiceId\}} - Update invoice specified by id.
\end{itemize}

The Modulith application has been extended to run in 3 modes, depending on the value of environment variables. In the first mode it runs as a single process. In the second mode it runs as a single process without invoice implementation and uses the invoice client. In the third mode it runs only the invoice implementation and this can be scaled to many instances to improve performance. Load balancing of requests to the invoice service instances is done using Nginx.

\begin{figure}
    \centering
    \includesvg[width=0.7\textwidth]{images/modulith_module_package.svg}
    \caption{Internal package structure of single module (Modulith example).\label{img:modulith_module_package}}
\end{figure}

\begin{figure}
    \centering
    \includesvg[width=0.7\textwidth]{images/modulith_package.svg}
    \caption{Module dependency graph of Modulith example. \label{img:modulith_package}}
\end{figure}

\subsection{Database}
Each module encapsulates its own tables, completely independent of the rest. The tables are the same as for the monolithic example on diagram~\ref{img:monolith_db_schema}, but the relations between modules have been removed. The schema consists of four partitions with relations preserved within the partition: the first partition consists of the invoice table, the second of the payment table, the third of the order table with rel\_item\_order and the last of the item, cart and rel\_item\_cart tables. Each module will have its own database pool with a maximum of 2 connections (8 in total).

% \begin{figure}
%     \centering
%     \includegraphics[width=\textwidth]{images/modulith_db_schema.png}
%     \caption{Database schema displaying tables and relations. \label{img:modulith_db_schema}}
% \end{figure}

\section{Microservices example}
In this example, the Modulith implementation has been further split into 5 microservices: Item, Shopping Cart, Invoice, Order and Payment. Modulith originally contained 4 packages, 1 of which combined the logic around Shopping Cart and Items, so it was split into two to make the scope more consistent across the microservices. The dependency graph between services is shown in Figure~\ref{img:microservices_dependency}.

Splitting Modulith into services requires exposing additional functionality over the network, as Modulith modules communicate with other modules via inter-process communication. As a result, additional endpoints (compared to the monolith) and clients had to be created to satisfy the defined interfaces.

% TODO přidat která další API musela vzniknout
\begin{itemize}
    \item \textbf{Post /invoice} - Generate invoice for order specified in body.
    \item \textbf{Patch /invoice/\{invoiceId\}} - Update invoice specified by id.
    \item \textbf{Delete /cart/\{cartId\}} - Remote cart specified by id.
    \item \textbf{Get /cart/\{cartId\}/item/id} - Retrieve item ids within cart.
    \item \textbf{Get /cart/user/\{userId\}} - Retrieve cart for user specified by user id.
\end{itemize}

Each microservice runs an HTTP server and exposes HTTP API for its internal API to be used by other modules and also public HTTP API to be used by clients. With microservices it is common to use some kind of service discovery and let services communicate directly with each other. In this example, to keep things simple, nginx was used as a load balancer, acting as an intermediary and directing requests to the right services by path matching.

The whole application is compiled into a single binary, but in production it would most likely be compiled into binaries per service. Which service is started is controlled by an environment variable.

\begin{figure}
    \centering
    \includesvg[width=0.7\textwidth]{images/microservices_dependency.svg}
    \caption{Dependency between microservices. \label{img:microservices_dependency}}
\end{figure}

\subsection{Database}
Each microservice encapsulates its own data. The database tables are the same as for the monolithic example on diagram~\ref{img:monolith_db_schema}, but the constraints outside the microservice scope have been removed. Database partitions are the same as for Modulith, only item table has been separated into its own service after splitting one package into two separate: cart and item. Each microservice will have its own database pool with a maximum of 2 connections (10 in total).

\input{text/benchmark}

